import { NextResponse } from "next/server";

export async function POST(req: Request) {
  try {
    const { prompt, systemPrompt, toolId, model = "gpt-4o-mini" } = await req.json();

    const openaiApiKey = process.env.OPENAI_API_KEY;
    const googleApiKey = process.env.GOOGLE_AI_API_KEY;

    // Advanced Mock Implementation if API keys are missing
    if ((model.startsWith("gpt") && !openaiApiKey) || (model.startsWith("gemini") && !googleApiKey)) {
      await new Promise((resolve) => setTimeout(resolve, 1500));
      
      const mockResponses: Record<string, string> = {
        "ai-text-generator": `[Generated by ${model.toUpperCase()}] Here is a high-quality draft based on your request: "${prompt}"\n\nI've analyzed the context and structured the content to be professional, engaging, and clear. Whether this is for an email, blog post, or report, it maintains a consistent tone and addresses all your key points effectively.`,
        "ai-summarizer": `[Generated by ${model.toUpperCase()}] Summary of your content:\n\n• CORE POINT: The text discusses the importance of efficient tool usage.\n• KEY DETAIL: Streamlining workflows leads to 40% higher productivity.\n• CONCLUSION: Integration of AI is no longer optional but a necessity for modern scaling.`,
        "ai-paraphraser": `[Generated by ${model.toUpperCase()}] Here is a refined version of your text:\n\n"Instead of just rephrasing, I've restructured the sentence to improve flow and impact while preserving your original intent. This version is more suitable for professional audiences."`,
        "ai-grammar-checker": `[Generated by ${model.toUpperCase()}] Analysis complete:\n\n1. "Their" changed to "There" (Homophone error)\n2. Added comma after "However" (Introductory phrase)\n3. Replaced "very good" with "exceptional" (Vocabulary enhancement)\n\nScore: 98/100`,
      };

      const responseText = mockResponses[toolId] || `This is an advanced ${model.toUpperCase()} response for ${toolId}.\n\nProcessed prompt: "${prompt}"\n\nIn a production environment, this would be generated by ${model} using the system context: "${systemPrompt || 'General Assistant'}".`;

      return NextResponse.json({ text: responseText });
    }

    if (model.startsWith("gpt")) {
      // Real OpenAI API Call
      const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${openaiApiKey}`,
        },
        body: JSON.stringify({
          model: model,
          messages: [
            { role: "system", content: systemPrompt || "You are a helpful assistant for Omnitools." },
            { role: "user", content: prompt },
          ],
          temperature: 0.7,
        }),
      });

      const data = await response.json();
      return NextResponse.json({ text: data.choices[0].message.content });
    } else if (model.startsWith("gemini")) {
      // Real Google Gemini API Call
      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${googleApiKey}`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          contents: [{
            parts: [{ text: `${systemPrompt}\n\nUser Prompt: ${prompt}` }]
          }]
        }),
      });

      const data = await response.json();
      return NextResponse.json({ text: data.candidates[0].content.parts[0].text });
    }

    return NextResponse.json({ error: "Unsupported model" }, { status: 400 });
  } catch (error) {
    console.error("AI API Error:", error);
    return NextResponse.json({ error: "Failed to generate AI response" }, { status: 500 });
  }
}
